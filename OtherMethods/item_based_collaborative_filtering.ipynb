{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = 'Data/'\n",
    "books = pd.read_csv(FOLDER_PATH + 'books.csv')\n",
    "sample_submission = pd.read_csv(FOLDER_PATH + 'sample_submission.csv')\n",
    "test = pd.read_csv(FOLDER_PATH + 'test.csv')\n",
    "train = pd.read_csv(FOLDER_PATH + 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-item matrix where the rows are comprised of user_ids\n",
    "# and the columns of book_ids. The values are the ratings\n",
    "user_item_matrix = train.pivot(index='user_id', columns='book_id', values='rating')\n",
    "user_item_matrix = user_item_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the item similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity = cosine_similarity(user_item_matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center the mean of the ratings for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_center_ignore_zeros(user_item_matrix):\n",
    "    user_item_matrix_np = user_item_matrix.values\n",
    "    \n",
    "    # Calculate mean ratings ignoring zero values\n",
    "    \n",
    "    # Sum of ratings per item\n",
    "    column_sums = user_item_matrix_np.sum(axis=0) \n",
    "    # Number of non-zero ratings per item\n",
    "    column_counts = (user_item_matrix_np > 0).sum(axis=0)  \n",
    "    item_means = np.divide(column_sums, column_counts, out=np.zeros_like(column_sums, dtype=float), where=column_counts != 0)  # Avoid division by zero\n",
    "\n",
    "    # Center the matrix by subtracting the mean (only for non-zero entries)\n",
    "    centered_matrix = user_item_matrix_np - item_means[np.newaxis,:]\n",
    "    # Keep the zero entries\n",
    "    centered_matrix[user_item_matrix_np == 0] = 0 \n",
    "\n",
    "    centered_df = pd.DataFrame(centered_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "    \n",
    "    return centered_df, item_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix with all the predictions in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_predict(user_item_matrix_df, item_similarity, k=10):\n",
    "    normalized_matrix, item_means = mean_center_ignore_zeros(user_item_matrix_df)\n",
    "    normalized_matrix_np = normalized_matrix.values\n",
    "    \n",
    "    # Apply top-k filtering to similarity matrix\n",
    "    top_k_similarities = np.zeros_like(item_similarity)\n",
    "    for i in range(item_similarity.shape[0]):\n",
    "        top_k_indices = np.argsort(-item_similarity[i])[:k]\n",
    "        top_k_similarities[i, top_k_indices] = item_similarity[i, top_k_indices]\n",
    "    \n",
    "    weighted_sum = normalized_matrix_np.dot(top_k_similarities)\n",
    "    sum_of_similarities = np.abs(normalized_matrix_np).dot((top_k_similarities > 0).astype(float))\n",
    "    #Prevent division by zero\n",
    "    sum_of_similarities[sum_of_similarities == 0] = 1e-8\n",
    "    predicted_ratings = (weighted_sum / sum_of_similarities) + item_means[np.newaxis,:]\n",
    "    # In case the ratings are outside the 1-5 range\n",
    "    predicted_ratings = np.clip(predicted_ratings, 1, 5)\n",
    "    \n",
    "    predicted_ratings_df = pd.DataFrame(predicted_ratings, index=user_item_matrix_df.index, columns=user_item_matrix_df.columns)\n",
    "    \n",
    "    return predicted_ratings_df\n",
    "\n",
    "predicted_ratings = item_based_predict(user_item_matrix, item_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that generates the submission.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(predicted_ratings):\n",
    "    submission = []\n",
    "    for index, row in test.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        book_id = row['book_id']\n",
    "        unique_id = row['id']  \n",
    "        predicted_rating = predicted_ratings.loc[user_id, book_id]\n",
    "        submission.append({'id': int(unique_id), 'rating': predicted_rating})\n",
    "    submission_df = pd.DataFrame(submission)\n",
    "    return submission_df\n",
    "\n",
    "submissions_df = make_submission(predicted_ratings)\n",
    "submissions_df.to_csv('submission_item_cf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disprojectii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
